{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxFXI5XxpPta"
      },
      "source": [
        "training_videos_folder = [\"/content/drive/MyDrive/dataset/Celeb-synthesis\"]\n",
        "# /content/drive/MyDrive/dataset/Celeb-synthesis\n",
        "for folder in training_videos_folder:\n",
        "    videos_path = glob.glob(join(folder, \"*.mp4\"))\n",
        "    folder = \"1\"\n",
        "\n",
        "    counter = 0\n",
        "    for video_path in videos_path:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        vid = video_path.split(\"/\")[-1]\n",
        "        vid = vid.split(\".\")[0]\n",
        "        frameRate = cap.get(5)  # frame rate\n",
        "\n",
        "        if not exists(\"../train_frames/\" + folder + \"/video_\" + str(int(counter))):\n",
        "            makedirs(\"../train_frames/\" + folder + \"/video_\" + str(int(counter)))\n",
        "\n",
        "        while cap.isOpened():\n",
        "            frameId = cap.get(1)  # current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            filename = (\"../train_frames/\"+ folder + \"/video_\"+ str(int(counter)) + \"/image_\"+ str(int(frameId) + 1)+ \".jpg\")\n",
        "            if frameId % 8 == 0:\n",
        "              cv2.imwrite(filename, frame)\n",
        "\n",
        "        cap.release()\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ4T-L8xprYK"
      },
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "mtcnn = MTCNN(\n",
        "    margin=40,\n",
        "    select_largest=False,\n",
        "    post_process=False\n",
        "    # device=\"cuda:0\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dop7P6a1p5BB"
      },
      "source": [
        "source_frames_folders = [\"/train_frames/0/\"]\n",
        "\n",
        "dest_faces_folder = \"../train_face/0/\"\n",
        "\n",
        "for i in source_frames_folders:\n",
        "    counter = 0\n",
        "    for j in listdir(i):\n",
        "        imgs = glob.glob(join(i, j, \"*.jpg\"))\n",
        "        if not exists(join(dest_faces_folder, j)):\n",
        "            makedirs(join(dest_faces_folder, j))\n",
        "        for img in imgs:\n",
        "            frame = cv2.imread(img)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = Image.fromarray(frame)\n",
        "            face = mtcnn(frame)\n",
        "\n",
        "            try:\n",
        "                imsave(\n",
        "                    join(dest_faces_folder, j, k.split(\"/\")[-1]),\n",
        "                    face.permute(1, 2, 0).int().numpy(),\n",
        "                )\n",
        "            except AttributeError:\n",
        "                print(\"Image un-abel to save hence skipping\")\n",
        "        counter += 1\n",
        "\n",
        "# for training of framesh with labels equals 1;\n",
        "\n",
        "\n",
        "# source_frames_folders = [\"/train_frames/1/\"]\n",
        "\n",
        "# dest_faces_folder = \"../train_face/1/\"\n",
        "\n",
        "# for i in source_frames_folders:\n",
        "#     counter = 0\n",
        "#     for j in listdir(i):\n",
        "#         imgs = glob.glob(join(i, j, \"*.jpg\"))\n",
        "#         if not exists(join(dest_faces_folder, j)):\n",
        "#             makedirs(join(dest_faces_folder, j))\n",
        "#         for img in imgs:\n",
        "#             frame = cv2.imread(img)\n",
        "#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#             frame = Image.fromarray(frame)\n",
        "#             face = mtcnn(frame)\n",
        "\n",
        "#             try:\n",
        "#                 imsave(\n",
        "#                     join(dest_faces_folder, j, k.split(\"/\")[-1]),\n",
        "#                     face.permute(1, 2, 0).int().numpy(),\n",
        "#                 )\n",
        "#             except AttributeError:\n",
        "#                 print(\"Image un-abel to save hence skipping\")\n",
        "#         counter += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYy6QCp8qZcb"
      },
      "source": [
        "!zip -r /content/file.zip /train_face/0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55FIRdWmswh9"
      },
      "source": [
        "# Images are an easier way to represent the working model. In Machine Learning,\n",
        "\n",
        "print(\"Welcome!\")\n",
        "frames_per_video = 47\n",
        "img_size = 160\n",
        "\n",
        "train_path = [\"/content/drive/MyDrive/dataset/train_face/1\", \"/content/drive/MyDrive/dataset/train_face/0\"]\n",
        "c = 0\n",
        "counter2 = 0\n",
        "counter = 0\n",
        "list_1 = [join(train_path[0], x) for x in listdir(train_path[0])]\n",
        "list_0 = [join(train_path[1], x) for x in listdir(train_path[1])]\n",
        "\n",
        "videoList = list_1 + list_0\n",
        "shuffle(videoList)\n",
        "train_data = []\n",
        "train_label = []\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "for i in videoList:\n",
        "    img = glob.glob(join(i, \"*.jpg\"))\n",
        "    img.sort(key=lambda f: int(\"\".join(filter(str.isdigit, f))))\n",
        "    images += img[: frames_per_video]\n",
        "    label = [x.split(\"/\")[-3] for x in img]\n",
        "    labels += label[: frames_per_video]\n",
        "\n",
        "    if counter % 10 == 0:\n",
        "      print(\"Number of images feeded\", counter)\n",
        "    counter += 1\n",
        "\n",
        "\n",
        "for j, k in zip(images, labels):\n",
        "\n",
        "    img = cv2.imread(j)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(\n",
        "      img, (img_size, img_size), interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "    train_data.append(img)\n",
        "    train_label += [k]\n",
        "\n",
        "    if counter2 % 10 == 0:\n",
        "       print(\"Number of files done:\", counter2)\n",
        "    counter2 += 1\n",
        "train_data = np.array(train_data)\n",
        "train_label = np.array(train_label)\n",
        "train_label = np_utils.to_categorical(train_label)\n",
        "\n",
        "np.save(\"train_data.npy\", train_data)\n",
        "np.save(\"train_label.npy\", train_label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}